{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "962327e1",
        "outputId": "d72d3d86-800b-4f8c-f5db-82cfbe6f8ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting covalent\n",
            "  Downloading covalent-0.220.0.post1.tar.gz (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiofiles<=22.1.0,>=0.8.0 (from covalent)\n",
            "  Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp==3.8.1 (from covalent)\n",
            "  Downloading aiohttp-3.8.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic<=1.8.1,>=1.8.0 (from covalent)\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click==8.1.3 (from covalent)\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle<=2.2.0,>=2.0.0 (from covalent)\n",
            "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting dask[distributed]<=2022.9.0,>=2022.6.0 (from covalent)\n",
            "  Downloading dask-2022.9.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<=0.83.0,>=0.79.0 (from covalent)\n",
            "  Downloading fastapi-0.83.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting furl==2.1.3 (from covalent)\n",
            "  Downloading furl-2.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Collecting networkx==2.8.6 (from covalent)\n",
            "  Downloading networkx-2.8.6-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil<=5.9.2,>=5.9.0 (from covalent)\n",
            "  Downloading psutil-5.9.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.8/282.8 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<=1.10.2,>=1.10.1 (from covalent)\n",
            "  Downloading pydantic-1.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-socketio==5.7.1 (from covalent)\n",
            "  Downloading python_socketio-5.7.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<=2.28.1,>=2.24.0 (from covalent)\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson==3.17.6 (from covalent)\n",
            "  Downloading simplejson-3.17.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.1/137.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy<=1.4.41,>=1.4.37 (from covalent)\n",
            "  Downloading SQLAlchemy-1.4.41-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy-utils==0.38.3 (from covalent)\n",
            "  Downloading SQLAlchemy_Utils-0.38.3-py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from covalent) (0.10.2)\n",
            "Collecting uvicorn[standard]<=0.18.3,>=0.18.2 (from covalent)\n",
            "  Downloading uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchdog==2.2.1 (from covalent)\n",
            "  Downloading watchdog-2.2.1-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m527.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug<=2.2.2,>=2.0.3 (from covalent)\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1->covalent) (23.1.0)\n",
            "Collecting charset-normalizer<3.0,>=2.0 (from aiohttp==3.8.1->covalent)\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1->covalent) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1->covalent) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1->covalent) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1->covalent) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.1->covalent) (1.3.1)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from furl==2.1.3->covalent) (1.16.0)\n",
            "Collecting orderedmultidict>=1.0.1 (from furl==2.1.3->covalent)\n",
            "  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting bidict>=0.21.0 (from python-socketio==5.7.1->covalent)\n",
            "  Downloading bidict-0.22.1-py3-none-any.whl (35 kB)\n",
            "Collecting python-engineio>=4.3.0 (from python-socketio==5.7.1->covalent)\n",
            "  Downloading python_engineio-4.7.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic<=1.8.1,>=1.8.0->covalent)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (23.2)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (0.12.0)\n",
            "Collecting distributed==2022.9.0 (from dask[distributed]<=2022.9.0,>=2022.6.0->covalent)\n",
            "  Downloading distributed-2022.9.0-py3-none-any.whl (902 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m902.4/902.4 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from distributed==2022.9.0->dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (3.1.2)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2022.9.0->dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2022.9.0->dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (1.0.7)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.10/dist-packages (from distributed==2022.9.0->dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2022.9.0->dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (2.0.0)\n",
            "Collecting tornado<6.2,>=6.0.3 (from distributed==2022.9.0->dask[distributed]<=2022.9.0,>=2022.6.0->covalent)\n",
            "  Downloading tornado-6.1.tar.gz (497 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.4/497.4 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from distributed==2022.9.0->dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (2.0.6)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2022.9.0->dask[distributed]<=2022.9.0,>=2022.6.0->covalent) (3.0.0)\n",
            "Collecting starlette==0.19.1 (from fastapi<=0.83.0,>=0.79.0->covalent)\n",
            "  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette==0.19.1->fastapi<=0.83.0,>=0.79.0->covalent) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<=1.10.2,>=1.10.1->covalent) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<=2.28.1,>=2.24.0->covalent) (3.4)\n",
            "Collecting urllib3 (from distributed==2022.9.0->dask[distributed]<=2022.9.0,>=2022.6.0->covalent)\n",
            "  Downloading urllib3-1.26.17-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<=2.28.1,>=2.24.0->covalent) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<=1.4.41,>=1.4.37->covalent) (3.0.0)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]<=0.18.3,>=0.18.2->covalent)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.4.0 (from uvicorn[standard]<=0.18.3,>=0.18.2->covalent)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]<=0.18.3,>=0.18.2->covalent)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]<=0.18.3,>=0.18.2->covalent)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]<=0.18.3,>=0.18.2->covalent)\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from uvicorn[standard]<=0.18.3,>=0.18.2->covalent)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug<=2.2.2,>=2.0.3->covalent) (2.1.3)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.3.0->python-socketio==5.7.1->covalent)\n",
            "  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi<=0.83.0,>=0.79.0->covalent) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi<=0.83.0,>=0.79.0->covalent) (1.1.3)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.3.0->python-socketio==5.7.1->covalent)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: covalent, tornado\n",
            "  Building wheel for covalent (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for covalent: filename=covalent-0.220.0.post1-py3-none-any.whl size=4040116 sha256=b9787c8224967ca0bcab0c350d634d6e9c155305bababfcbecc0898eb413278a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/31/71/a4777373912fe0773675b787b605a06071bdd4c4f7c681996e\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.1-cp310-cp310-linux_x86_64.whl size=421979 sha256=7c9e306d3effea21df9a34435a895307321a4e750dd2f3770d485f59e2041ab7\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/32/8d/21cf0fa6ee4e083f6530e5b83dfdfa9489a3890d320803f4c7\n",
            "Successfully built covalent tornado\n",
            "Installing collected packages: werkzeug, websockets, watchdog, uvloop, urllib3, tornado, sqlalchemy, simplejson, python-dotenv, pydantic, psutil, orderedmultidict, networkx, Mako, httptools, h11, cloudpickle, click, charset-normalizer, bidict, aiofiles, wsproto, watchfiles, uvicorn, starlette, sqlalchemy-utils, requests, furl, dask, alembic, aiohttp, simple-websocket, fastapi, distributed, python-engineio, python-socketio, covalent\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.0\n",
            "    Uninstalling Werkzeug-3.0.0:\n",
            "      Successfully uninstalled Werkzeug-3.0.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.6\n",
            "    Uninstalling urllib3-2.0.6:\n",
            "      Successfully uninstalled urllib3-2.0.6\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.3.2\n",
            "    Uninstalling tornado-6.3.2:\n",
            "      Successfully uninstalled tornado-6.3.2\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.21\n",
            "    Uninstalling SQLAlchemy-2.0.21:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.21\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 2.2.1\n",
            "    Uninstalling cloudpickle-2.2.1:\n",
            "      Successfully uninstalled cloudpickle-2.2.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.0\n",
            "    Uninstalling charset-normalizer-3.3.0:\n",
            "      Successfully uninstalled charset-normalizer-3.3.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2023.8.1\n",
            "    Uninstalling dask-2023.8.1:\n",
            "      Successfully uninstalled dask-2023.8.1\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.8.5\n",
            "    Uninstalling aiohttp-3.8.5:\n",
            "      Successfully uninstalled aiohttp-3.8.5\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2023.8.1\n",
            "    Uninstalling distributed-2023.8.1:\n",
            "      Successfully uninstalled distributed-2023.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.1 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado==6.3.2, but you have tornado 6.1 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.41 which is incompatible.\n",
            "yfinance 0.2.30 requires requests>=2.31, but you have requests 2.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.2.4 aiofiles-22.1.0 aiohttp-3.8.1 alembic-1.8.1 bidict-0.22.1 charset-normalizer-2.1.1 click-8.1.3 cloudpickle-2.2.0 covalent-0.220.0.post1 dask-2022.9.0 distributed-2022.9.0 fastapi-0.83.0 furl-2.1.3 h11-0.14.0 httptools-0.6.0 networkx-2.8.6 orderedmultidict-1.0.1 psutil-5.9.2 pydantic-1.10.2 python-dotenv-1.0.0 python-engineio-4.7.1 python-socketio-5.7.1 requests-2.28.1 simple-websocket-1.0.0 simplejson-3.17.6 sqlalchemy-1.4.41 sqlalchemy-utils-0.38.3 starlette-0.19.1 tornado-6.1 urllib3-1.26.17 uvicorn-0.18.3 uvloop-0.17.0 watchdog-2.2.1 watchfiles-0.20.0 websockets-11.0.3 werkzeug-2.2.2 wsproto-1.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "charset_normalizer",
                  "cloudpickle",
                  "psutil",
                  "requests",
                  "tornado",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PennyLane\n",
            "  Downloading PennyLane-0.32.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24 in /usr/local/lib/python3.10/dist-packages (from PennyLane) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from PennyLane) (1.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from PennyLane) (2.8.6)\n",
            "Collecting rustworkx (from PennyLane)\n",
            "  Downloading rustworkx-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autograd<=1.5 (from PennyLane)\n",
            "  Downloading autograd-1.5-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from PennyLane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from PennyLane) (1.4.4)\n",
            "Collecting semantic-version>=2.7 (from PennyLane)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting autoray>=0.3.1 (from PennyLane)\n",
            "  Downloading autoray-0.6.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from PennyLane) (5.3.1)\n",
            "Collecting pennylane-lightning>=0.32 (from PennyLane)\n",
            "  Downloading PennyLane_Lightning-0.32.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from PennyLane) (2.28.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from PennyLane) (4.5.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd<=1.5->PennyLane) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->PennyLane) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->PennyLane) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->PennyLane) (1.26.17)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->PennyLane) (2023.7.22)\n",
            "Installing collected packages: semantic-version, rustworkx, autoray, autograd, pennylane-lightning, PennyLane\n",
            "  Attempting uninstall: autograd\n",
            "    Found existing installation: autograd 1.6.2\n",
            "    Uninstalling autograd-1.6.2:\n",
            "      Successfully uninstalled autograd-1.6.2\n",
            "Successfully installed PennyLane-0.32.0 autograd-1.5 autoray-0.6.6 pennylane-lightning-0.32.0 rustworkx-0.13.2 semantic-version-2.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install covalent\n",
        "!pip install PennyLane"
      ],
      "id": "962327e1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFgczN0wjUNl"
      },
      "outputs": [],
      "source": [
        "import covalent as ct\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Set up Covalent server\n",
        "os.environ[\"COVALENT_SERVER_IFACE_ANY\"] = \"1\"\n",
        "os.system(\"covalent start\")\n",
        "# If you run into any out-of-memory issues with Dask when running this notebook,\n",
        "# Try reducing the number of workers and making a specific memory request. I.e.:\n",
        "# os.system(\"covalent start -m \"2GiB\" -n 2\")\n",
        "# try covalent –help for more info\n",
        "time.sleep(2)  # give the Dask cluster some time to launch"
      ],
      "id": "AFgczN0wjUNl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28180d06"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import scipy.io\n",
        "\n",
        "# Seed Torch for reproducibility and set default tensor type\n",
        "GLOBAL_SEED = 1989\n",
        "torch.manual_seed(GLOBAL_SEED)\n",
        "torch.set_default_tensor_type(torch.DoubleTensor)\n",
        "\n",
        "mat = scipy.io.loadmat('features_sensor2_d0.mat')\n",
        "X_all = torch.from_numpy(mat['features_data'])\n",
        "\n",
        "mat_anorm = scipy.io.loadmat('features_sensor2_d1.mat')\n",
        "Y_all = torch.from_numpy(mat_anorm['features_data'])\n",
        "\n",
        "@ct.electron\n",
        "def generate_normal_time_series_set(\n",
        "    split_data: int, X_all: float, p: int, num_series: int, noise_amp: float, t_init: float, t_end: float, seed: int = GLOBAL_SEED\n",
        ") -> tuple:\n",
        "    \"\"\"Generate a normal time series data set where each of the p elements\n",
        "    is drawn from a normal distribution x_t ~ N(0, noise_amp).\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    if split_data == 1:    #Split data for train\n",
        "     X=X_all[0:50,:]\n",
        "    elif split_data == 2:  #Split data for threshold optimization\n",
        "     X=X_all[50:100,:]\n",
        "    else:                  #Split data for test\n",
        "     X=X_all[100:150,:]\n",
        "\n",
        "    T = torch.linspace(0, 1, 11) #usando matriz 25x25 igual o original\n",
        "    return X, T\n",
        "\n",
        "\n",
        "@ct.electron\n",
        "def generate_anomalous_time_series_set(\n",
        "    split_data: int,\n",
        "    Y_all: float,\n",
        "    p: int,\n",
        "    num_series: int,\n",
        "    noise_amp: float,\n",
        "    spike_amp: float,\n",
        "    max_duration: int,\n",
        "    t_init: float,\n",
        "    t_end: float,\n",
        "    seed: int = GLOBAL_SEED,\n",
        ") -> tuple:\n",
        "    \"\"\"Generate an anomalous time series data set where the p elements of each sequence are\n",
        "    from a normal distribution x_t ~ N(0, noise_amp). Then,\n",
        "    anomalous spikes of random amplitudes and durations are inserted.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    if split_data == 1:\n",
        "     Y=Y_all[0:50,:] #usando matriz 25x25 igual o original\n",
        "    elif split_data == 2:\n",
        "     Y=Y_all[50:100,:]\n",
        "    else:\n",
        "     Y=Y_all[100:150,:]\n",
        "    T = torch.linspace(0, 1, 11) #usando matriz 25x25 igual o original\n",
        "    return Y, T"
      ],
      "id": "28180d06"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "b4047061",
        "outputId": "9d7d1dda-06c5-4d0f-83cf-3958542b343b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_norm, T_norm = generate_normal_time_series_set(1,X_all, 25, 25, 0.1, 0.1, 2 * torch.pi)\n",
        "Y_anom, T_anom = generate_anomalous_time_series_set(1,Y_all, 25, 25, 0.1, 0.4, 5, 0, 2 * torch.pi)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(T_norm, X_norm[0], label=\"Normal\")\n",
        "plt.plot(T_anom, Y_anom[0], label=\"Anomalous\")\n",
        "plt.ylabel(\"$y(t)$\")\n",
        "plt.xlabel(\"t\")\n",
        "plt.grid()\n",
        "leg = plt.legend()"
      ],
      "id": "b4047061"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e66cc40"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "def make_atomized_training_set(X: torch.Tensor, T: torch.Tensor) -> list:\n",
        "    \"\"\"Convert input time series data provided in a two-dimensional tensor format\n",
        "    to atomized tuple chunks: (xt, t).\n",
        "    \"\"\"\n",
        "    X_flat = torch.flatten(X)\n",
        "    T_flat = T.repeat(X.size()[0])\n",
        "    atomized = [(xt, t) for xt, t in zip(X_flat, T_flat)]\n",
        "    return atomized"
      ],
      "id": "3e66cc40"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ae9f25c"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Iterator\n",
        "\n",
        "\n",
        "class DataGetter:\n",
        "    \"\"\"A pickleable mock-up of a Python iterator on a torch.utils.Dataloader.\n",
        "    Provide a dataset X and the resulting object O will allow you to use next(O).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X: torch.Tensor, batch_size: int, seed: int = GLOBAL_SEED) -> None:\n",
        "        \"\"\"Calls the _init_data method on intialization of a DataGetter object.\"\"\"\n",
        "        torch.manual_seed(seed)\n",
        "        self.X = X\n",
        "        self.batch_size = batch_size\n",
        "        self.data = []\n",
        "        self._init_data(\n",
        "            iter(torch.utils.data.DataLoader(self.X, batch_size=self.batch_size, shuffle=True))\n",
        "        )\n",
        "\n",
        "    def _init_data(self, iterator: Iterator) -> None:\n",
        "        \"\"\"Load all of the iterator into a list.\"\"\"\n",
        "        x = next(iterator, None)\n",
        "        while x is not None:\n",
        "            self.data.append(x)\n",
        "            x = next(iterator, None)\n",
        "\n",
        "    def __next__(self) -> tuple:\n",
        "        \"\"\"Analogous behaviour to the native Python next() but calling the\n",
        "        .pop() of the data attribute.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.data.pop()\n",
        "        except IndexError:  # Caught when the data set runs out of elements\n",
        "            self._init_data(\n",
        "                iter(torch.utils.data.DataLoader(self.X, batch_size=self.batch_size, shuffle=True))\n",
        "            )\n",
        "            return self.data.pop()"
      ],
      "id": "1ae9f25c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53a3686f"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "def get_training_cycler(Xtr: torch.Tensor, batch_size: int, seed: int = GLOBAL_SEED) -> DataGetter:\n",
        "    \"\"\"Get an instance of the DataGetter class defined above, which behaves analogously to\n",
        "    next(iterator) but is pickleable.\n",
        "    \"\"\"\n",
        "    return DataGetter(Xtr, batch_size, seed)"
      ],
      "id": "53a3686f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "032b96f6"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "from itertools import combinations\n",
        "\n",
        "\n",
        "@ct.electron\n",
        "def D(gamma: torch.Tensor, n_qubits: int, k: int = None, get_probs: bool = False) -> None:\n",
        "    \"\"\"Generates an n_qubit quantum circuit according to a k-local Walsh operator\n",
        "    expansion. Here, k-local means that 1 <= k <= n of the n qubits can interact.\n",
        "    See <https://doi.org/10.1088/1367-2630/16/3/033040> for more\n",
        "    details. Optionally return probabilities of bit strings.\n",
        "    \"\"\"\n",
        "    if k is None:\n",
        "        k = n_qubits\n",
        "    cnt = 0\n",
        "    for i in range(1, k + 1):\n",
        "        for comb in combinations(range(n_qubits), i):\n",
        "            if len(comb) == 1:\n",
        "                qml.RZ(gamma[cnt], wires=[comb[0]])\n",
        "                cnt += 1\n",
        "            elif len(comb) > 1:\n",
        "                cnots = [comb[i : i + 2] for i in range(len(comb) - 1)]\n",
        "                for j in cnots:\n",
        "                    qml.CNOT(wires=j)\n",
        "                qml.RZ(gamma[cnt], wires=[comb[-1]])\n",
        "                cnt += 1\n",
        "                for j in cnots[::-1]:\n",
        "                    qml.CNOT(wires=j)\n",
        "    if get_probs:\n",
        "        return qml.probs(wires=range(n_qubits))"
      ],
      "id": "032b96f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8ef0aae"
      },
      "outputs": [],
      "source": [
        "n_qubits = 5\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits, shots=None)\n",
        "#D_one_qubit = qml.qnode(dev)(D)\n",
        "#_ = qml.draw_mpl(D_one_qubit, decimals=2)(torch.tensor([1, 0]), 1, 1, True)"
      ],
      "id": "e8ef0aae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa1c2859"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "@qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
        "def get_probs(\n",
        "    xt: torch.Tensor,\n",
        "    t: float,\n",
        "    alpha: torch.Tensor,\n",
        "    gamma: torch.Tensor,\n",
        "    k: int,\n",
        "    U: callable,\n",
        "    W: callable,\n",
        "    D: callable,\n",
        "    n_qubits: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Measure the probabilities for measuring each bitstring after applying a\n",
        "    circuit of the form W†DWU to the |0⟩^(⊗n) state. This\n",
        "    function is defined for individual sequence elements xt.\n",
        "    \"\"\"\n",
        "    U(xt, wires=range(n_qubits))\n",
        "    W(alpha, wires=range(n_qubits))\n",
        "    D(gamma * t, n_qubits, k)\n",
        "    qml.adjoint(W)(alpha, wires=range(n_qubits))\n",
        "    return qml.probs(range(n_qubits))"
      ],
      "id": "aa1c2859"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97f9f13f"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "def get_callable_projector_func(\n",
        "    k: int, U: callable, W: callable, D: callable, n_qubits: int, probs_func: callable\n",
        ") -> callable:\n",
        "    \"\"\"Using get_probs() above, take only the probability of measuring the\n",
        "    bitstring of all zeroes (i.e, take the projector\n",
        "    |0⟩^(⊗n)⟨0|^(⊗n)) on the time devolved state.\n",
        "    \"\"\"\n",
        "    callable_proj = lambda xt, t, alpha, gamma: probs_func(\n",
        "        xt, t, alpha, gamma, k, U, W, D, n_qubits\n",
        "    )[0]\n",
        "    return callable_proj"
      ],
      "id": "97f9f13f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a46c0b52"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "def F(\n",
        "    callable_proj: callable,\n",
        "    xt: torch.Tensor,\n",
        "    t: float,\n",
        "    alpha: torch.Tensor,\n",
        "    mu: torch.Tensor,\n",
        "    sigma: torch.Tensor,\n",
        "    gamma_length: int,\n",
        "    n_samples: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Take the classical expecation value of of the projector on zero sampling\n",
        "    the parameters of D from normal distributions. The expecation value is estimated\n",
        "    with an average over n_samples.\n",
        "    \"\"\"\n",
        "    # length of gamma should not exceed 2^n - 1\n",
        "    gammas = sigma.abs() * torch.randn((n_samples, gamma_length)) + mu\n",
        "    expectation = torch.empty(n_samples)\n",
        "    for i, gamma in enumerate(gammas):\n",
        "        expectation[i] = callable_proj(xt, t, alpha, gamma)\n",
        "    return expectation.mean()"
      ],
      "id": "a46c0b52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b492d5b"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "def callable_arctan_penalty(tau: float) -> callable:\n",
        "    \"\"\"Create a callable arctan function with a single hyperparameter\n",
        "    tau to penalize large entries of sigma.\n",
        "    \"\"\"\n",
        "    prefac = 1 / (torch.pi)\n",
        "    callable_pen = lambda sigma: prefac * torch.arctan(2 * torch.pi * tau * sigma.abs()).mean()\n",
        "    return callable_pen"
      ],
      "id": "9b492d5b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb4de5dc"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "def get_loss(\n",
        "    callable_proj: callable,\n",
        "    batch: torch.Tensor,\n",
        "    alpha: torch.Tensor,\n",
        "    mu: torch.Tensor,\n",
        "    sigma: torch.Tensor,\n",
        "    gamma_length: int,\n",
        "    n_samples: int,\n",
        "    callable_penalty: callable,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Evaluate the loss function ℒ, defined in the background section\n",
        "    for a certain set of parameters.\n",
        "    \"\"\"\n",
        "    X_batch, T_batch = batch\n",
        "    loss = torch.empty(X_batch.size()[0])\n",
        "    for i in range(X_batch.size()[0]):\n",
        "        # unsqueeze required for tensor to have the correct dimension for PennyLane templates\n",
        "        loss[i] = (\n",
        "            1\n",
        "            - F(\n",
        "                callable_proj,\n",
        "                X_batch[i].unsqueeze(0),\n",
        "                T_batch[i].unsqueeze(0),\n",
        "                alpha,\n",
        "                mu,\n",
        "                sigma,\n",
        "                gamma_length,\n",
        "                n_samples,\n",
        "            )\n",
        "        ).square()\n",
        "    return 0.5 * loss.mean() + callable_penalty(sigma)"
      ],
      "id": "fb4de5dc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d179a48f"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "def get_initial_parameters(\n",
        "    W: callable, W_layers: int, n_qubits: int, seed: int = GLOBAL_SEED\n",
        ") -> dict:\n",
        "    \"\"\"Randomly generate initial parameters. We need initial parameters for the\n",
        "    variational circuit ansatz implementing W(alpha) and the standard deviation\n",
        "    and mean (sigma and mu) for the normal distribution we sample gamma from.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    init_alpha = torch.rand(W.shape(W_layers, n_qubits))\n",
        "    init_mu = torch.rand(1)\n",
        "    # Best to start sigma small and expand if needed\n",
        "    init_sigma = torch.rand(1)\n",
        "    init_params = {\n",
        "        \"alpha\": (2 * torch.pi * init_alpha).clone().detach().requires_grad_(True),\n",
        "        \"mu\": (2 * torch.pi * init_mu).clone().detach().requires_grad_(True),\n",
        "        \"sigma\": (0.1 * init_sigma + 0.05).clone().detach().requires_grad_(True),\n",
        "    }\n",
        "    return init_params"
      ],
      "id": "d179a48f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f51d18d"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "def train_model_gradients(\n",
        "    lr: float,\n",
        "    init_params: dict,\n",
        "    pytorch_optimizer: callable,\n",
        "    cycler: DataGetter,\n",
        "    n_samples: int,\n",
        "    callable_penalty: callable,\n",
        "    batch_iterations: int,\n",
        "    callable_proj: callable,\n",
        "    gamma_length: int,\n",
        "    seed=GLOBAL_SEED,\n",
        "    print_intermediate=False,\n",
        ") -> dict:\n",
        "    \"\"\"Train the QVR model (minimize the loss function) with respect to the\n",
        "    variational parameters using gradient-based training. You need to pass a\n",
        "    PyTorch optimizer and a learning rate (lr).\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    opt = pytorch_optimizer(init_params.values(), lr=lr)\n",
        "    alpha = init_params[\"alpha\"]\n",
        "    mu = init_params[\"mu\"]\n",
        "    sigma = init_params[\"sigma\"]\n",
        "\n",
        "    def closure():\n",
        "        opt.zero_grad()\n",
        "        loss = get_loss(\n",
        "            callable_proj, next(cycler), alpha, mu, sigma, gamma_length, n_samples, callable_penalty\n",
        "        )\n",
        "        loss.backward()\n",
        "        return loss\n",
        "\n",
        "    loss_history = []\n",
        "    for i in range(batch_iterations):\n",
        "        loss = opt.step(closure)\n",
        "        loss_history.append(loss.item())\n",
        "        if batch_iterations % 10 == 0 and print_intermediate:\n",
        "            print(f\"Iteration number {i}\\n Current loss {loss.item()}\\n\")\n",
        "\n",
        "    results_dict = {\n",
        "        \"opt_params\": {\n",
        "            \"alpha\": opt.param_groups[0][\"params\"][0],\n",
        "            \"mu\": opt.param_groups[0][\"params\"][1],\n",
        "            \"sigma\": opt.param_groups[0][\"params\"][2],\n",
        "        },\n",
        "        \"loss_history\": loss_history,\n",
        "    }\n",
        "    return results_dict"
      ],
      "id": "9f51d18d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9c70834"
      },
      "outputs": [],
      "source": [
        "@ct.lattice\n",
        "def training_workflow(\n",
        "    U: callable,\n",
        "    W: callable,\n",
        "    D: callable,\n",
        "    n_qubits: int,\n",
        "    k: int,\n",
        "    probs_func: callable,\n",
        "    W_layers: int,\n",
        "    gamma_length: int,\n",
        "    n_samples: int,\n",
        "    split_data: int,\n",
        "    X_all: float,\n",
        "    p: int,\n",
        "    num_series: int,\n",
        "    noise_amp: float,\n",
        "    t_init: float,\n",
        "    t_end: float,\n",
        "    batch_size: int,\n",
        "    tau: float,\n",
        "    pytorch_optimizer: callable,\n",
        "    lr: float,\n",
        "    batch_iterations: int,\n",
        "):\n",
        "    \"\"\"\n",
        "    Combine all of the previously defined electrons to do an entire training workflow,\n",
        "    including (1) generating synthetic data, (2) packaging it into training cyclers\n",
        "    (3) preparing the quantum functions and (4) optimizing the loss function with\n",
        "    gradient based optimization. You can find definitions for all of the arguments\n",
        "    by looking at the electrons and text cells above.\n",
        "    \"\"\"\n",
        "\n",
        "    X, T = generate_normal_time_series_set(split_data,X_all, p, num_series, noise_amp, t_init, t_end)\n",
        "    Xtr = make_atomized_training_set(X, T)\n",
        "    cycler = get_training_cycler(Xtr, batch_size)\n",
        "    init_params = get_initial_parameters(W, W_layers, n_qubits)\n",
        "    callable_penalty = callable_arctan_penalty(tau)\n",
        "    callable_proj = get_callable_projector_func(k, U, W, D, n_qubits, probs_func)\n",
        "    results_dict = train_model_gradients(\n",
        "        lr,\n",
        "        init_params,\n",
        "        pytorch_optimizer,\n",
        "        cycler,\n",
        "        n_samples,\n",
        "        callable_penalty,\n",
        "        batch_iterations,\n",
        "        callable_proj,\n",
        "        gamma_length,\n",
        "        print_intermediate=False,\n",
        "    )\n",
        "    return results_dict"
      ],
      "id": "f9c70834"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c4a9f86"
      },
      "outputs": [],
      "source": [
        "general_options = {\n",
        "    \"U\": qml.AngleEmbedding,\n",
        "    \"W\": qml.StronglyEntanglingLayers,\n",
        "    \"D\": D,\n",
        "    \"n_qubits\": 1,\n",
        "    \"probs_func\": get_probs,\n",
        "    \"gamma_length\": 1,\n",
        "    \"n_samples\": 10,\n",
        "    \"p\": 22,\n",
        "    \"num_series\": 25,\n",
        "    \"noise_amp\": 0.1,\n",
        "    \"t_init\": 0.1,\n",
        "    \"t_end\": 2 * torch.pi,\n",
        "    \"k\": 1,\n",
        "}\n",
        "\n",
        "training_options = {\n",
        "    \"batch_size\": 10,\n",
        "    \"tau\": 5,\n",
        "    \"split_data\": 1, #training data\n",
        "    \"X_all\": X_all,\n",
        "    \"pytorch_optimizer\": torch.optim.Adam,\n",
        "    \"lr\": 0.01,\n",
        "    \"batch_iterations\": 1200,\n",
        "    \"W_layers\": 2,\n",
        "}\n",
        "\n",
        "training_options.update(general_options)"
      ],
      "id": "5c4a9f86"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c664a977"
      },
      "outputs": [],
      "source": [
        "tr_dispatch_id = ct.dispatch(training_workflow)(**training_options)"
      ],
      "id": "c664a977"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz8o3sWrxAsv"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.getrecursionlimit())\n",
        "sys.setrecursionlimit(10000)"
      ],
      "id": "wz8o3sWrxAsv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2beab384",
        "outputId": "ac30c6cc-5e09-41d0-d0d2-5c1d7052d132"
      },
      "outputs": [
        {
          "ename": "RecursionError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2665ec770006>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mct_tr_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr_dispatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct_tr_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/covalent/_results_manager/results_manager.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(dispatch_id, wait, dispatcher_addr, status_only)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         result = _get_result_from_dispatcher(\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mdispatch_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/covalent/_results_manager/results_manager.py\u001b[0m in \u001b[0;36m_get_result_from_dispatcher\u001b[0;34m(dispatch_id, wait, dispatcher_addr, status_only)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mresult_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{dispatcher_addr}/api/result/{dispatch_id}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     response = http.get(\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mresult_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"wait\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"status_only\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstatus_only\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreferred_clock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeoutSauce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mcert_reqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0mkey_password\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0mca_certs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0mssl_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0massert_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "... last 1 frames repeated, from the frame below ...\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mcert_reqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0mkey_password\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0mca_certs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0mssl_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0massert_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
          ]
        }
      ],
      "source": [
        "ct_tr_results = ct.get_result(dispatch_id=tr_dispatch_id, wait=True)\n",
        "results_dict = ct_tr_results.result"
      ],
      "id": "2beab384"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "41414fcb"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(results_dict[\"loss_history\"], \".-\")\n",
        "plt.ylabel(\"Loss [$\\mathcal{L}$]\")\n",
        "plt.xlabel(\"Batch iterations\")\n",
        "plt.title(\"Loss function versus batch iterations in training\")\n",
        "plt.grid()"
      ],
      "id": "41414fcb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0b3c064a"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "def get_preds_given_threshold(zeta: float, scores: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"For a given threshold, get the predicted labels (1 or -1), given the anomaly scores.\"\"\"\n",
        "    return torch.tensor([-1 if score > zeta else 1 for score in scores])\n",
        "\n",
        "\n",
        "@ct.electron\n",
        "def get_truth_labels(\n",
        "    normal_series_set: torch.Tensor, anomalous_series_set: torch.Tensor\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Get a 1D tensor containing the truth values (1 or -1) for a given set of\n",
        "    time series.\n",
        "    \"\"\"\n",
        "    norm = torch.ones(normal_series_set.size()[0])\n",
        "    anom = -torch.ones(anomalous_series_set.size()[0])\n",
        "    return torch.cat([norm, anom])\n",
        "\n",
        "\n",
        "@ct.electron\n",
        "def get_accuracy_score(pred: torch.Tensor, truth: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Given the predictions and truth values, return a number between 0 and 1\n",
        "    indicating the accuracy of predictions.\n",
        "    \"\"\"\n",
        "    return torch.sum(pred == truth) / truth.size()[0]"
      ],
      "id": "0b3c064a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d6821c61"
      },
      "outputs": [],
      "source": [
        "@ct.electron\n",
        "def threshold_scan_acc_score(\n",
        "    scores: torch.Tensor, truth_labels: torch.Tensor, zeta_min: float, zeta_max: float, steps: int\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Given the anomaly scores and truth values,\n",
        "    scan over a range of thresholds = [zeta_min, zeta_max] with a\n",
        "    fixed number of steps, calculating the accuracy score at each point.\n",
        "    \"\"\"\n",
        "    accs = torch.empty(steps)\n",
        "    for i, zeta in enumerate(torch.linspace(zeta_min, zeta_max, steps)):\n",
        "        preds = get_preds_given_threshold(zeta, scores)\n",
        "        accs[i] = get_accuracy_score(preds, truth_labels)\n",
        "    return accs\n",
        "\n",
        "\n",
        "@ct.electron\n",
        "def get_anomaly_score(\n",
        "    callable_proj: callable,\n",
        "    y: torch.Tensor,\n",
        "    T: torch.Tensor,\n",
        "    alpha_star: torch.Tensor,\n",
        "    mu_star: torch.Tensor,\n",
        "    sigma_star: torch.Tensor,\n",
        "    gamma_length: int,\n",
        "    n_samples: int,\n",
        "    get_time_resolved: bool = False,\n",
        "):\n",
        "    \"\"\"Get the anomaly score for an input time series y. We need to pass the\n",
        "    optimal parameters (arguments with suffix _star). Optionally return the\n",
        "    time-resolved score (the anomaly score contribution at a given t).\n",
        "    \"\"\"\n",
        "    scores = torch.empty(T.size()[0])\n",
        "    for i in range(T.size()[0]):\n",
        "        scores[i] = (\n",
        "            1\n",
        "            - F(\n",
        "                callable_proj,\n",
        "                y[i].unsqueeze(0),\n",
        "                T[i].unsqueeze(0),\n",
        "                alpha_star,\n",
        "                mu_star,\n",
        "                sigma_star,\n",
        "                gamma_length,\n",
        "                n_samples,\n",
        "            )\n",
        "        ).square()\n",
        "    if get_time_resolved:\n",
        "        return scores, scores.mean()\n",
        "    else:\n",
        "        return scores.mean()\n",
        "\n",
        "\n",
        "@ct.electron\n",
        "def get_norm_and_anom_scores(\n",
        "    X_norm: torch.Tensor,\n",
        "    X_anom: torch.Tensor,\n",
        "    T: torch.Tensor,\n",
        "    callable_proj: callable,\n",
        "    model_params: dict,\n",
        "    gamma_length: int,\n",
        "    n_samples: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Get the anomaly scores assigned to input normal and anomalous time series instances.\n",
        "    model_params is a dictionary containing the optimal model parameters.\n",
        "    \"\"\"\n",
        "    alpha = model_params[\"alpha\"]\n",
        "    mu = model_params[\"mu\"]\n",
        "    sigma = model_params[\"sigma\"]\n",
        "    norm_scores = torch.tensor(\n",
        "        [\n",
        "            get_anomaly_score(callable_proj, xt, T, alpha, mu, sigma, gamma_length, n_samples)\n",
        "            for xt in X_norm\n",
        "        ]\n",
        "    )\n",
        "    anom_scores = torch.tensor(\n",
        "        [\n",
        "            get_anomaly_score(callable_proj, xt, T, alpha, mu, sigma, gamma_length, n_samples)\n",
        "            for xt in X_anom\n",
        "        ]\n",
        "    )\n",
        "    return torch.cat([norm_scores, anom_scores])"
      ],
      "id": "d6821c61"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c63aa261"
      },
      "outputs": [],
      "source": [
        "@ct.lattice\n",
        "def threshold_tuning_workflow(\n",
        "    opt_params: dict,\n",
        "    gamma_length: int,\n",
        "    n_samples: int,\n",
        "    probs_func: callable,\n",
        "    zeta_min: float,\n",
        "    zeta_max: float,\n",
        "    steps: int,\n",
        "    split_data: int,\n",
        "    X_all: float,\n",
        "    Y_all: float,\n",
        "    p: int,\n",
        "    num_series: int,\n",
        "    noise_amp: float,\n",
        "    spike_amp: float,\n",
        "    max_duration: int,\n",
        "    t_init: float,\n",
        "    t_end: float,\n",
        "    k: int,\n",
        "    U: callable,\n",
        "    W: callable,\n",
        "    D: callable,\n",
        "    n_qubits: int,\n",
        "    random_model_seeds: torch.Tensor,\n",
        "    W_layers: int,\n",
        ") -> tuple:\n",
        "    \"\"\"A workflow for tuning the threshold value zeta, in order to maximize the accuracy score\n",
        "    for a validation data set. Results are tested against random models at their optimal zetas.\n",
        "    \"\"\"\n",
        "    # Generate datasets\n",
        "    X_val_norm, T = generate_normal_time_series_set(split_data, X_all, p, num_series, noise_amp, t_init, t_end)\n",
        "    X_val_anom, T = generate_anomalous_time_series_set(\n",
        "        2, Y_all, p, num_series, noise_amp, spike_amp, max_duration, t_init, t_end\n",
        "    )\n",
        "    truth_labels = get_truth_labels(X_val_norm, X_val_anom)\n",
        "\n",
        "    # Initialize quantum functions\n",
        "    callable_proj = get_callable_projector_func(k, U, W, D, n_qubits, probs_func)\n",
        "\n",
        "    accs_list = []\n",
        "    scores_list = []\n",
        "    # Evaluate optimal model\n",
        "    scores = get_norm_and_anom_scores(\n",
        "        X_val_norm, X_val_anom, T, callable_proj, opt_params, gamma_length, n_samples\n",
        "    )\n",
        "    accs_opt = threshold_scan_acc_score(scores, truth_labels, zeta_min, zeta_max, steps)\n",
        "    accs_list.append(accs_opt)\n",
        "    scores_list.append(scores)\n",
        "\n",
        "    # Evaluate random models\n",
        "    for seed in random_model_seeds:\n",
        "        rand_params = get_initial_parameters(W, W_layers, n_qubits, seed)\n",
        "        scores = get_norm_and_anom_scores(\n",
        "            X_val_norm, X_val_anom, T, callable_proj, rand_params, gamma_length, n_samples\n",
        "        )\n",
        "        accs_list.append(threshold_scan_acc_score(scores, truth_labels, zeta_min, zeta_max, steps))\n",
        "        scores_list.append(scores)\n",
        "    return accs_list, scores_list"
      ],
      "id": "c63aa261"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b8959aa1"
      },
      "outputs": [],
      "source": [
        "threshold_tuning_options = {\n",
        "    \"spike_amp\": 0.4,\n",
        "    \"max_duration\": 5,\n",
        "    \"zeta_min\": 0,\n",
        "    \"zeta_max\": 1,\n",
        "    \"split_data\": 2, #theshhold tunning data\n",
        "    \"X_all\": X_all,\n",
        "    \"Y_all\": Y_all,\n",
        "    \"steps\": 100000,\n",
        "    \"random_model_seeds\": [0, 1],\n",
        "    \"W_layers\": 2,\n",
        "    \"opt_params\": results_dict[\"opt_params\"],\n",
        "}\n",
        "\n",
        "threshold_tuning_options.update(general_options)"
      ],
      "id": "b8959aa1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4241d968"
      },
      "outputs": [],
      "source": [
        "val_dispatch_id = ct.dispatch(threshold_tuning_workflow)(**threshold_tuning_options)\n",
        "ct_val_results = ct.get_result(dispatch_id=val_dispatch_id, wait=True)\n",
        "accs_list, scores_list = ct_val_results.result"
      ],
      "id": "4241d968"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "67941451"
      },
      "outputs": [],
      "source": [
        "#zeta_xlims = [(0, 0.001), (0.25, 0.38), (0.25, 0.38)]\n",
        "zeta_xlims = [(0, 1), (0, 1), (0, 1)]\n",
        "titles = [\"Trained model\", \"Random model 1\", \"Random model 2\"]\n",
        "zetas = torch.linspace(\n",
        "    threshold_tuning_options[\"zeta_min\"],\n",
        "    threshold_tuning_options[\"zeta_max\"],\n",
        "    threshold_tuning_options[\"steps\"],\n",
        ")\n",
        "fig, axs = plt.subplots(ncols=3, nrows=2, sharey=\"row\")\n",
        "for i in range(3):\n",
        "    axs[0, i].plot(zetas, accs_list[i])\n",
        "    axs[0, i].set_xlim(zeta_xlims[i])\n",
        "    axs[0, i].set_xlabel(\"Threshold [$\\zeta$]\")\n",
        "    axs[0, i].set_title(titles[i])\n",
        "    axs[1, i].boxplot(\n",
        "        [\n",
        "            scores_list[i][0 : general_options[\"num_series\"]],\n",
        "            scores_list[i][general_options[\"num_series\"] : -1],\n",
        "        ],\n",
        "        labels=[\"Normal\", \"Anomalous\"],\n",
        "    )\n",
        "    axs[1, i].set_yscale(\"log\")\n",
        "    axs[1, i].axhline(\n",
        "        zetas[torch.argmax(accs_list[i])], color=\"k\", linestyle=\":\", label=\"Optimal $\\zeta$\"\n",
        "    )\n",
        "    axs[1, i].legend()\n",
        "axs[0, 0].set_ylabel(\"Accuracy score\")\n",
        "axs[1, 0].set_ylabel(\"Anomaly score [$a_X(y)$]\")\n",
        "fig.tight_layout()"
      ],
      "id": "67941451"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7f26aa7d"
      },
      "outputs": [],
      "source": [
        "@ct.lattice\n",
        "def testing_workflow(\n",
        "    opt_params: dict,\n",
        "    gamma_length: int,\n",
        "    n_samples: int,\n",
        "    probs_func: callable,\n",
        "    best_zetas: list,\n",
        "    p: int,\n",
        "    split_data: int,\n",
        "    X_all: float,\n",
        "    Y_all: float,\n",
        "    num_series: int,\n",
        "    noise_amp: float,\n",
        "    spike_amp: float,\n",
        "    max_duration: int,\n",
        "    t_init: float,\n",
        "    t_end: float,\n",
        "    k: int,\n",
        "    U: callable,\n",
        "    W: callable,\n",
        "    D: callable,\n",
        "    n_qubits: int,\n",
        "    random_model_seeds: torch.Tensor,\n",
        "    W_layers: int,\n",
        ") -> list:\n",
        "    \"\"\"A workflow for calculating anomaly scores for a set of testing time series\n",
        "    given an optimal model and set of random models. We use the optimal zetas found in threshold tuning.\n",
        "    \"\"\"\n",
        "    # Generate time series\n",
        "    X_val_norm, T = generate_normal_time_series_set(split_data, X_all, p, num_series, noise_amp, t_init, t_end)\n",
        "    X_val_anom, T = generate_anomalous_time_series_set(\n",
        "        split_data, Y_all, p, num_series, noise_amp, spike_amp, max_duration, t_init, t_end\n",
        "    )\n",
        "    truth_labels = get_truth_labels(X_val_norm, X_val_anom)\n",
        "\n",
        "    # Prepare quantum functions\n",
        "    callable_proj = get_callable_projector_func(k, U, W, D, n_qubits, probs_func)\n",
        "\n",
        "    accs_list = []\n",
        "    # Evaluate optimal model\n",
        "    scores = get_norm_and_anom_scores(\n",
        "        X_val_norm, X_val_anom, T, callable_proj, opt_params, gamma_length, n_samples\n",
        "    )\n",
        "    preds = get_preds_given_threshold(best_zetas[0], scores)\n",
        "    accs_list.append(get_accuracy_score(preds, truth_labels))\n",
        "    # Evaluate random models\n",
        "    for zeta, seed in zip(best_zetas[1:], random_model_seeds):\n",
        "        rand_params = get_initial_parameters(W, W_layers, n_qubits, seed)\n",
        "        scores = get_norm_and_anom_scores(\n",
        "            X_val_norm, X_val_anom, T, callable_proj, rand_params, gamma_length, n_samples\n",
        "        )\n",
        "        preds = get_preds_given_threshold(zeta, scores)\n",
        "        accs_list.append(get_accuracy_score(preds, truth_labels))\n",
        "    return accs_list"
      ],
      "id": "7f26aa7d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e8190545"
      },
      "outputs": [],
      "source": [
        "testing_options = {\n",
        "    \"spike_amp\": 0.4,\n",
        "    \"max_duration\": 5,\n",
        "    \"split_data\": 3, #testing data\n",
        "    \"X_all\": X_all,\n",
        "    \"Y_all\": Y_all,\n",
        "    \"best_zetas\": [zetas[torch.argmax(accs)] for accs in accs_list],\n",
        "    \"random_model_seeds\": [0, 1],\n",
        "    \"W_layers\": 2,\n",
        "    \"opt_params\": results_dict[\"opt_params\"],\n",
        "}\n",
        "\n",
        "testing_options.update(general_options)\n",
        "\n",
        "test_dispatch_id = ct.dispatch(testing_workflow)(**testing_options)\n",
        "ct_test_results = ct.get_result(dispatch_id=test_dispatch_id, wait=True)\n",
        "accs_list = ct_test_results.result"
      ],
      "id": "e8190545"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eb32ee38"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.bar([1, 2, 3], accs_list)\n",
        "plt.axhline(0.5, color=\"k\", linestyle=\":\", label=\"Random accuracy\")\n",
        "plt.xticks([1, 2, 3], [\"Trained model\", \"Random model 1\", \"Random model 2\"])\n",
        "plt.ylabel(\"Accuracy score\")\n",
        "plt.title(\"Accuracy scores for trained and random models\")\n",
        "leg = plt.legend()"
      ],
      "id": "eb32ee38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d7b18f27"
      },
      "outputs": [],
      "source": [
        "# Shut down the covalent server\n",
        "stop = os.system(\"covalent stop\")"
      ],
      "id": "d7b18f27"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}